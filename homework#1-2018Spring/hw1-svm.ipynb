{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/dennis/SourceCode/NCTU-Machine-Learning/homework#1-2018Spring/libsvm-master/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svm\n",
    "import svmutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "%matplotlib inline\n",
    "os.chdir('/home/dennis/SourceCode/NCTU-Machine-Learning/homework#1-2018Spring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n",
      "(5000, 1)\n",
      "(2500, 784)\n",
      "(2500, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('./data/X_train.csv', header=None)\n",
    "T_train = pd.read_csv('./data/T_train.csv', header=None)\n",
    "X_test = pd.read_csv('./data/X_test.csv', header=None)\n",
    "T_test = pd.read_csv('./data/T_test.csv', header=None)\n",
    "print(X_train.shape)\n",
    "print(T_train.shape)\n",
    "print(X_test.shape)\n",
    "print(T_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dict = X_train.to_dict('records')\n",
    "X_test_dict = X_test.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_train_list = T_train[0].tolist()\n",
    "T_test_list = T_test[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Use different kernel functions (linear, polynomial, and RBF kernels) and have comparison between their performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_prob = svm.svm_problem(T_train_list, X_train_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model supports probability estimates, but disabled in predicton.\n",
      "Accuracy = 95.08% (2377/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "svm_param = svm.svm_parameter('-t 0 -b 1')\n",
    "model_linear = svmutil.svm_train(svm_prob, svm_param)\n",
    "p_label, p_acc, p_val = svmutil.svm_predict(T_test_list, X_test_dict, model_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model supports probability estimates, but disabled in predicton.\n",
      "Accuracy = 34.72% (868/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "svm_param = svm.svm_parameter('-t 1 -b 1')\n",
    "model_poly = svmutil.svm_train(svm_prob, svm_param)\n",
    "p_label, p_acc, p_val = svmutil.svm_predict(T_test_list, X_test_dict, model_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model supports probability estimates, but disabled in predicton.\n",
      "Accuracy = 95.32% (2382/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "svm_param = svm.svm_parameter('-t 2 -b 1')\n",
    "model_rbf = svmutil.svm_train(svm_prob, svm_param)\n",
    "p_label, p_acc, p_val = svmutil.svm_predict(T_test_list, X_test_dict, model_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Please use C-SVC (you can choose by setting parameters in the function input, C-SVC is soft-margin SVM). Since there are some parameters you need to tune for, please do the grid search for finding parameters of best performing model. For instance, in C-SVC you have a parameter C, and if you use RBF kernel you have another parameter γ, you can search for a set of (C,γ) which gives you best performance in cross-validation. (lots of sources on internet, just google for it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter list(gamma and C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [10 ** d for d in range(-4, 5)]\n",
    "gamma = [10 ** d for d in range(-4, 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(C, gamma, fold, full_data, full_target):\n",
    "#     fold_size = len(full_data) // fold\n",
    "    svm_param = svm.svm_parameter('-t 2 -c {} -g {} -v {}'.format(C, gamma, fold))\n",
    "    svm_prob = svm.svm_problem(full_target, full_data)\n",
    "    acc = svmutil.svm_train(svm_prob, svm_param)\n",
    "    return acc\n",
    "#     for f in range(fold):\n",
    "#         # Prepare training data and validation data\n",
    "#         X_val = full_data[fold * fold_size: (fold+1) * fold_size]\n",
    "#         T_val = full_target[fold * fold_size: (fold+1) * fold_size]\n",
    "#         X_train = full_data[0 * fold_size : fold * fold_size] + full_data[(fold+1) * fold_size:]\n",
    "#         T_train = full_target[0 * fold_size : fold * fold_size] + full_target[(fold+1) * fold_size:]\n",
    "        \n",
    "#         # Setup svm problem and model\n",
    "#         svm_prob = svm.svm_problem(T_train, X_train)\n",
    "#         model_rbf = svmutil.svm_train(svm_prob, svm_param)\n",
    "        \n",
    "#         _, p_acc, _ = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 79.58%\n",
      "Cross Validation Accuracy = 81.1%\n",
      "Cross Validation Accuracy = 89.88%\n",
      "Cross Validation Accuracy = 48.14%\n",
      "Cross Validation Accuracy = 20.68%\n",
      "Cross Validation Accuracy = 78.8%\n",
      "Cross Validation Accuracy = 36.02%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 79.58%\n",
      "Cross Validation Accuracy = 80.94%\n",
      "Cross Validation Accuracy = 89.78%\n",
      "Cross Validation Accuracy = 49.72%\n",
      "Cross Validation Accuracy = 20.36%\n",
      "Cross Validation Accuracy = 78.92%\n",
      "Cross Validation Accuracy = 36.14%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 79.48%\n",
      "Cross Validation Accuracy = 81.06%\n",
      "Cross Validation Accuracy = 92.26%\n",
      "Cross Validation Accuracy = 49.08%\n",
      "Cross Validation Accuracy = 20.78%\n",
      "Cross Validation Accuracy = 78.86%\n",
      "Cross Validation Accuracy = 36.26%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 79.72%\n",
      "Cross Validation Accuracy = 92.44%\n",
      "Cross Validation Accuracy = 96.18%\n",
      "Cross Validation Accuracy = 53.42%\n",
      "Cross Validation Accuracy = 20.82%\n",
      "Cross Validation Accuracy = 78.94%\n",
      "Cross Validation Accuracy = 36.12%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 92.42%\n",
      "Cross Validation Accuracy = 96.16%\n",
      "Cross Validation Accuracy = 97.84%\n",
      "Cross Validation Accuracy = 91.54%\n",
      "Cross Validation Accuracy = 30.08%\n",
      "Cross Validation Accuracy = 20.26%\n",
      "Cross Validation Accuracy = 36.38%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 96.16%\n",
      "Cross Validation Accuracy = 97.26%\n",
      "Cross Validation Accuracy = 98.2%\n",
      "Cross Validation Accuracy = 92.08%\n",
      "Cross Validation Accuracy = 32.88%\n",
      "Cross Validation Accuracy = 25.46%\n",
      "Cross Validation Accuracy = 36.12%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 97.04%\n",
      "Cross Validation Accuracy = 97.1%\n",
      "Cross Validation Accuracy = 98.14%\n",
      "Cross Validation Accuracy = 91.96%\n",
      "Cross Validation Accuracy = 31.3%\n",
      "Cross Validation Accuracy = 30.34%\n",
      "Cross Validation Accuracy = 36.16%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 96.62%\n",
      "Cross Validation Accuracy = 96.92%\n",
      "Cross Validation Accuracy = 98.16%\n",
      "Cross Validation Accuracy = 91.9%\n",
      "Cross Validation Accuracy = 31.76%\n",
      "Cross Validation Accuracy = 25.5%\n",
      "Cross Validation Accuracy = 36.08%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 96.18%\n",
      "Cross Validation Accuracy = 96.9%\n",
      "Cross Validation Accuracy = 98.26%\n",
      "Cross Validation Accuracy = 91.86%\n",
      "Cross Validation Accuracy = 30.8%\n",
      "Cross Validation Accuracy = 25.5%\n",
      "Cross Validation Accuracy = 36.06%\n",
      "Cross Validation Accuracy = 20%\n",
      "Cross Validation Accuracy = 20%\n",
      "Best parameter pair is (10000, 0.01)\n",
      "Best Acc: 98.26\n"
     ]
    }
   ],
   "source": [
    "best_pair = (0, 0)\n",
    "best_acc = 0\n",
    "for cost in C:\n",
    "    for g in gamma:\n",
    "        acc = CrossValidation(cost, g, 4, X_train_dict, T_train_list)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_pair = (cost, g)\n",
    "print('Best parameter pair is ({}, {})'.format(best_pair[0], best_pair[1]))\n",
    "print('Best Acc: {}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use best parameters to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.16% (2454/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "svm_param = svm.svm_parameter('-t 2 -c {} -g {}'.format(best_pair[0], best_pair[1]))\n",
    "svm_prob = svm.svm_problem(T_train_list, X_train_dict)\n",
    "model_rbf_best = svmutil.svm_train(svm_prob, svm_param)\n",
    "p_label, p_acc, p_val = svmutil.svm_predict(T_test_list, X_test_dict, model_rbf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Use linear kernel+RBF kernel together (therefore a new kernel function) and compare its performance with respect to others. You would need to find out how to use a user-defined kernel in libsvm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare user-defined kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel, linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n",
      "(2500, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_mat = X_train.as_matrix()\n",
    "X_test_mat = X_test.as_matrix()\n",
    "print(X_train_mat.shape)\n",
    "print(X_test_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 5000)\n"
     ]
    }
   ],
   "source": [
    "custom_kernel = rbf_kernel(X_train_mat, gamma=best_pair[1]) + linear_kernel(X_train_mat)\n",
    "print(custom_kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_kernel_list = custom_kernel.tolist()\n",
    "for i in range(len(custom_kernel_list)):\n",
    "    custom_kernel_list[i].insert(0, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use parameters learned before\n",
    "svm_param = svm.svm_parameter('-t 4 -c {} -g {} -b 1'.format(best_pair[0], best_pair[1]))\n",
    "svm_prob = svm.svm_problem(T_train_list, custom_kernel_list, isKernel=True)\n",
    "model = svmutil.svm_train(svm_prob, svm_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create kernel between training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 5000)\n"
     ]
    }
   ],
   "source": [
    "test_kernel = rbf_kernel(X_test_mat, X_train_mat, gamma=best_pair[1]) + linear_kernel(X_test_mat, X_train_mat)\n",
    "print(test_kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel_list = test_kernel.tolist()\n",
    "for i in range(len(test_kernel_list)):\n",
    "    test_kernel_list[i].insert(0, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model supports probability estimates, but disabled in predicton.\n",
      "Accuracy = 95.32% (2382/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svmutil.svm_predict(T_test_list, test_kernel_list, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
